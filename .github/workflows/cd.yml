name: CD

on:
  push:
    branches: [main]
    paths-ignore:
      - 'docs/**'
      - '**/*.md'
      - '.github/workflows/ci.yml'
  workflow_dispatch:

# Prevent concurrent deployments - cancel older pending deploys when new push arrives
concurrency:
  group: staging-deploy
  cancel-in-progress: true

env:
  AWS_REGION: us-west-2

jobs:
  # Debounce: wait 5 minutes to allow multiple rapid pushes to settle
  debounce:
    name: Debounce (5 min)
    runs-on: ubuntu-latest
    outputs:
      should_deploy: ${{ steps.check.outputs.should_deploy }}
    steps:
      - name: Wait 5 minutes
        run: |
          echo "Waiting 5 minutes to debounce rapid pushes..."
          sleep 300

      - name: Check if this is still the latest commit
        id: check
        run: |
          # Get the latest commit on main
          RESPONSE=$(curl -sf -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            "https://api.github.com/repos/${{ github.repository }}/commits/main")

          if [ $? -ne 0 ]; then
            echo "Failed to fetch latest commit from GitHub API"
            echo "Proceeding with deploy to avoid blocking on API issues"
            echo "should_deploy=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          LATEST=$(echo "$RESPONSE" | jq -r '.sha')

          if [ -z "$LATEST" ] || [ "$LATEST" = "null" ]; then
            echo "Failed to parse commit SHA from API response"
            echo "Proceeding with deploy to avoid blocking on API issues"
            echo "should_deploy=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "This workflow commit: ${{ github.sha }}"
          echo "Latest main commit:   $LATEST"

          if [ "${{ github.sha }}" = "$LATEST" ]; then
            echo "This is the latest commit, proceeding with deploy"
            echo "should_deploy=true" >> $GITHUB_OUTPUT
          else
            echo "Newer commits exist, skipping this deploy"
            echo "should_deploy=false" >> $GITHUB_OUTPUT
          fi

  # Wait for CI to pass
  ci-check:
    name: Wait for CI
    runs-on: ubuntu-latest
    needs: debounce
    if: needs.debounce.outputs.should_deploy == 'true'
    steps:
      - name: Wait for CI workflow
        uses: lewagon/wait-on-check-action@v1.3.4
        with:
          ref: ${{ github.sha }}
          check-name: 'Build Production Images'
          repo-token: ${{ secrets.GITHUB_TOKEN }}
          wait-interval: 10

  deploy:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: ci-check
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 22
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build packages
        run: pnpm build

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_DEPLOY_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push API image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./api/Dockerfile
          push: true
          tags: |
            ${{ steps.login-ecr.outputs.registry }}/doc-platform/api:latest
            ${{ steps.login-ecr.outputs.registry }}/doc-platform/api:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build and push Frontend image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./frontend/Dockerfile
          push: true
          tags: |
            ${{ steps.login-ecr.outputs.registry }}/doc-platform/frontend:latest
            ${{ steps.login-ecr.outputs.registry }}/doc-platform/frontend:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build and push MCP image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./mcp/Dockerfile
          push: true
          tags: |
            ${{ steps.login-ecr.outputs.registry }}/doc-platform/mcp:latest
            ${{ steps.login-ecr.outputs.registry }}/doc-platform/mcp:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Get stack outputs
        id: stack
        run: |
          OUTPUTS=$(aws cloudformation describe-stacks \
            --stack-name DocPlatformStack \
            --query "Stacks[0].Outputs" \
            --output json \
            --region ${{ env.AWS_REGION }})

          echo "task_def=$(echo $OUTPUTS | jq -r '.[] | select(.OutputKey=="ApiTaskDefinitionArn") | .OutputValue')" >> $GITHUB_OUTPUT
          echo "subnets=$(echo $OUTPUTS | jq -r '.[] | select(.OutputKey=="PrivateSubnetIds") | .OutputValue')" >> $GITHUB_OUTPUT
          echo "security_group=$(echo $OUTPUTS | jq -r '.[] | select(.OutputKey=="ApiSecurityGroupId") | .OutputValue')" >> $GITHUB_OUTPUT
          echo "alb_dns=$(echo $OUTPUTS | jq -r '.[] | select(.OutputKey=="AlbDnsName") | .OutputValue')" >> $GITHUB_OUTPUT
          echo "log_group=$(echo $OUTPUTS | jq -r '.[] | select(.OutputKey=="ApiLogGroupName") | .OutputValue')" >> $GITHUB_OUTPUT
          echo "cluster=$(echo $OUTPUTS | jq -r '.[] | select(.OutputKey=="ClusterName") | .OutputValue')" >> $GITHUB_OUTPUT

      - name: Run database migrations
        id: migrate
        run: |
          # Parse subnets into JSON array format
          SUBNETS_JSON=$(echo '${{ steps.stack.outputs.subnets }}' | tr ',' '\n' | jq -R . | jq -s .)

          # Validate subnets array is non-empty
          SUBNET_COUNT=$(echo "$SUBNETS_JSON" | jq 'length')
          if [ "$SUBNET_COUNT" -eq 0 ]; then
            echo "Error: No subnets found in stack outputs"
            exit 1
          fi
          echo "Found $SUBNET_COUNT subnets"

          # Run migration task using the API task definition with overridden command
          TASK_ARN=$(aws ecs run-task \
            --cluster ${{ steps.stack.outputs.cluster }} \
            --task-definition ${{ steps.stack.outputs.task_def }} \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={subnets=${SUBNETS_JSON},securityGroups=[\"${{ steps.stack.outputs.security_group }}\"],assignPublicIp=DISABLED}" \
            --overrides '{
              "containerOverrides": [{
                "name": "api",
                "command": ["node", "shared/db/dist/migrate.js"]
              }]
            }' \
            --query 'tasks[0].taskArn' \
            --output text \
            --region ${{ env.AWS_REGION }})

          echo "task_arn=$TASK_ARN" >> $GITHUB_OUTPUT
          echo "Started migration task: $TASK_ARN"

      - name: Wait for migration to complete
        run: |
          echo "Waiting for migration task to complete..."
          aws ecs wait tasks-stopped \
            --cluster ${{ steps.stack.outputs.cluster }} \
            --tasks ${{ steps.migrate.outputs.task_arn }} \
            --region ${{ env.AWS_REGION }}

          # Check exit code
          EXIT_CODE=$(aws ecs describe-tasks \
            --cluster ${{ steps.stack.outputs.cluster }} \
            --tasks ${{ steps.migrate.outputs.task_arn }} \
            --query 'tasks[0].containers[0].exitCode' \
            --output text \
            --region ${{ env.AWS_REGION }})

          echo "Migration task exit code: $EXIT_CODE"

          if [ "$EXIT_CODE" != "0" ]; then
            echo "Migration failed! Fetching logs..."

            # Get task ID from ARN
            TASK_ID=$(echo "${{ steps.migrate.outputs.task_arn }}" | rev | cut -d'/' -f1 | rev)

            # Dynamically discover the log stream
            LOG_STREAM=$(aws logs describe-log-streams \
              --log-group-name "${{ steps.stack.outputs.log_group }}" \
              --log-stream-name-prefix "api/api/${TASK_ID}" \
              --query 'logStreams[0].logStreamName' \
              --output text \
              --region ${{ env.AWS_REGION }}) || true

            if [ -n "$LOG_STREAM" ] && [ "$LOG_STREAM" != "None" ]; then
              echo "Log stream: $LOG_STREAM"
              aws logs get-log-events \
                --log-group-name "${{ steps.stack.outputs.log_group }}" \
                --log-stream-name "$LOG_STREAM" \
                --limit 100 \
                --region ${{ env.AWS_REGION }} \
                --query 'events[*].message' \
                --output text || echo "Could not fetch log events"
            else
              echo "Could not find log stream for task ${TASK_ID}"
            fi

            exit 1
          fi

          echo "Migration completed successfully!"

      - name: Seed admin account
        id: seed
        run: |
          # Parse subnets into JSON array format
          SUBNETS_JSON=$(echo '${{ steps.stack.outputs.subnets }}' | tr ',' '\n' | jq -R . | jq -s .)

          # Run seed task using the API task definition with overridden command and env vars
          TASK_ARN=$(aws ecs run-task \
            --cluster ${{ steps.stack.outputs.cluster }} \
            --task-definition ${{ steps.stack.outputs.task_def }} \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={subnets=${SUBNETS_JSON},securityGroups=[\"${{ steps.stack.outputs.security_group }}\"],assignPublicIp=DISABLED}" \
            --overrides '{
              "containerOverrides": [{
                "name": "api",
                "command": ["node", "shared/db/dist/seed.js"],
                "environment": [
                  {"name": "ADMIN_USERNAME", "value": "${{ secrets.ADMIN_USERNAME }}"},
                  {"name": "ADMIN_PASSWORD", "value": "${{ secrets.ADMIN_PASSWORD }}"},
                  {"name": "ADMIN_EMAIL", "value": "${{ secrets.ADMIN_EMAIL }}"},
                  {"name": "ADMIN_FIRST_NAME", "value": "${{ secrets.ADMIN_FIRST_NAME }}"},
                  {"name": "ADMIN_LAST_NAME", "value": "${{ secrets.ADMIN_LAST_NAME }}"}
                ]
              }]
            }' \
            --query 'tasks[0].taskArn' \
            --output text \
            --region ${{ env.AWS_REGION }})

          echo "task_arn=$TASK_ARN" >> $GITHUB_OUTPUT
          echo "Started seed task: $TASK_ARN"

      - name: Wait for seed to complete
        run: |
          echo "Waiting for seed task to complete..."
          aws ecs wait tasks-stopped \
            --cluster ${{ steps.stack.outputs.cluster }} \
            --tasks ${{ steps.seed.outputs.task_arn }} \
            --region ${{ env.AWS_REGION }}

          # Check exit code
          EXIT_CODE=$(aws ecs describe-tasks \
            --cluster ${{ steps.stack.outputs.cluster }} \
            --tasks ${{ steps.seed.outputs.task_arn }} \
            --query 'tasks[0].containers[0].exitCode' \
            --output text \
            --region ${{ env.AWS_REGION }})

          echo "Seed task exit code: $EXIT_CODE"

          if [ "$EXIT_CODE" != "0" ]; then
            echo "Seed failed! Fetching logs..."

            # Get task ID from ARN
            TASK_ID=$(echo "${{ steps.seed.outputs.task_arn }}" | rev | cut -d'/' -f1 | rev)

            # Dynamically discover the log stream
            LOG_STREAM=$(aws logs describe-log-streams \
              --log-group-name "${{ steps.stack.outputs.log_group }}" \
              --log-stream-name-prefix "api/api/${TASK_ID}" \
              --query 'logStreams[0].logStreamName' \
              --output text \
              --region ${{ env.AWS_REGION }}) || true

            if [ -n "$LOG_STREAM" ] && [ "$LOG_STREAM" != "None" ]; then
              echo "Log stream: $LOG_STREAM"
              aws logs get-log-events \
                --log-group-name "${{ steps.stack.outputs.log_group }}" \
                --log-stream-name "$LOG_STREAM" \
                --limit 100 \
                --region ${{ env.AWS_REGION }} \
                --query 'events[*].message' \
                --output text || echo "Could not fetch log events"
            else
              echo "Could not find log stream for task ${TASK_ID}"
            fi

            exit 1
          fi

          echo "Seed completed successfully!"

      - name: Deploy infrastructure
        run: |
          cd infra
          npx cdk deploy --require-approval never

      - name: Force new deployment
        run: |
          # Force ECS to pull latest images (in case CDK didn't trigger updates)
          aws ecs update-service \
            --cluster ${{ steps.stack.outputs.cluster }} \
            --service api \
            --force-new-deployment \
            --region ${{ env.AWS_REGION }}
          aws ecs update-service \
            --cluster ${{ steps.stack.outputs.cluster }} \
            --service frontend \
            --force-new-deployment \
            --region ${{ env.AWS_REGION }}
          aws ecs update-service \
            --cluster ${{ steps.stack.outputs.cluster }} \
            --service mcp \
            --force-new-deployment \
            --region ${{ env.AWS_REGION }}

      - name: Wait for services to stabilize
        run: |
          echo "Waiting for all services to stabilize (up to 20 minutes)..."
          aws ecs wait services-stable \
            --cluster ${{ steps.stack.outputs.cluster }} \
            --services api frontend mcp \
            --region ${{ env.AWS_REGION }}

      - name: Deployment complete
        run: |
          echo "Deployed to: http://${{ steps.stack.outputs.alb_dns }}"
